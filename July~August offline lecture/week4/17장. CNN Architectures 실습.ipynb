{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet\n",
    "## 개요\n",
    "17장에서는 컴퓨터 성능이 좋아지며 발전해온 여러 CNN의 Architecture에 대해 실습해보겠습니다.\n",
    "\n",
    "LeNet은 최초의 CNN 모델로 Yann LeCun에 의해 1998년에 나온 모델입니다.\n",
    "\n",
    "LeNet은 머신 러닝에서 사용하던 단순한 Fully Connected Layer(MLP)의 한계를 극복하고자 Convoultion 연산을 처음 도입한 인공신경망입니다.\n",
    "\n",
    "https://kasausyrzlhe1066469.cdn.ntruss.com/global/file/p/5d2ff087bba5a479aae58340/LeNet.PNG\n",
    "\n",
    "### 구조\n",
    "LeNet은 우편번호와 수표의 필기체를 인식하기위해 개발되었으며 총 7개의 Layer로 구성되어 있습니다.\n",
    "\n",
    "---------------------------------\n",
    "\n",
    "### LeNet 구조\n",
    "\n",
    "* Convolution Layer : 2개\n",
    "* Sub-Sampling Layer : 2개\n",
    "* Fully Connected Layer : 2개\n",
    "* Output Layer : 10개의 Class 구분\n",
    "* 파라미터 개수 - 61007개\n",
    "\n",
    "-----------------------------\n",
    "### 실습\n",
    "작성된 LeNet Model을 보고 분석해보세요.\n",
    "\n",
    "summary() 메서드를 통해 출력된 구조와 파라미터 개수를 확인해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "# LeNet Model\n",
    "def LeNet():\n",
    "    model = keras.Sequential()\n",
    "    # Conv 1 Layer\n",
    "    model.add(keras.layers.Conv2D(filters=6, kernel_size=5, strides = 1, activation=tf.nn.relu, input_shape=(32, 32, 1)))\n",
    "    \n",
    "    # Sub Sampling Layer (Max Pooling)\n",
    "    model.add(keras.layers.MaxPool2D(pool_size = 2, strides =2))\n",
    "    \n",
    "    # Conv 1 Layer\n",
    "    model.add(keras.layers.Conv2D(filters=16, kernel_size=5, strides = 1, activation=tf.nn.relu, input_shape= (16, 16, 1)))\n",
    "    \n",
    "    # Sub Sampling Layer (Max Pooling)\n",
    "    model.add(keras.layers.MaxPool2D(pool_size = 2, strides =2))\n",
    "    \n",
    "    # Fully Connected (FC) Layer와 연결하기 위한 Flatten\n",
    "    model.add(keras.layers.Flatten())\n",
    "    \n",
    "    # FC1 Layer \n",
    "    model.add(keras.layers.Dense(120, activation=tf.nn.relu))\n",
    "    # FC2 Layer\n",
    "    model.add(keras.layers.Dense(84, activation=tf.nn.relu))\n",
    "    \n",
    "    # Output Softmax\n",
    "    model.add(keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "    return model\n",
    "    \n",
    "lenet = LeNet()\n",
    "lenet.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet\n",
    "### 개요\n",
    "AlexNet은 ILSVRC 2012(ImageNet Large Scale Visual Recognition Challenge) 대회에서 우승한 모델로 GPU를 사용해 계산량 문제를 해결했습니다.\n",
    "\n",
    "https://kasausyrzlhe1066469.cdn.ntruss.com/global/file/p/5d31156993667819c3af811b/AlexNet.PNG\n",
    "\n",
    "AlexNet은 2개의 GPU를 병렬로 이용해 데이터를 학습시키고 특정 Layer에서만 학습된 Feature를 공유하도록 만들었습니다.\n",
    "\n",
    "### ImageNet Dataset\n",
    "AlexNet은 영상의 Class 분류를 위해 설계되었으며 데이터는 ImageNet을 사용했습니다.\n",
    "\n",
    "AlexNet에 사용된 ImageNet 데이터는 약 150만장으로 구성되어있으며 Train 120만장, Validation 5만장, Test 15만장으로 구성되어있습니다.\n",
    "\n",
    "이를 통해 1000개의 Class를 분류하도록 구성된 영상 데이터입니다.\n",
    "\n",
    "### 구조\n",
    "AlexNet 구조는 LeNet과 비슷하지만 LeNet보다 더 깊은 형태의 신경망으로 구성되어 있습니다.\n",
    "\n",
    "---------------------------\n",
    "* Convolution Layer : 5개\n",
    "* Fully Connected Layer : 3개\n",
    "* ReLU Activation Function 적용\n",
    "* Drop Out 적용\n",
    "\n",
    "관련 링크 - https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\n",
    "\n",
    "### 실습\n",
    "Keras로 작성된 AlexNet 구조를 보고 이해해보세요.\n",
    "\n",
    "summary() 메서드를 통해 각 Layer의 구조, 필터 개수, 커널 크기 등을 확인해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 96)        34944     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 28, 28, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 256)       614656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 384)       885120    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 5, 5, 256)         884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4096)              9441280   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 34,066,792\n",
      "Trainable params: 34,066,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "# AlexNet Model\n",
    "def AlexNet():\n",
    "    # Sequential 모델 선언\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # 첫 번째 Convolutional Layer\n",
    "    model.add(keras.layers.Conv2D(filters=96, kernel_size= 11, strides=4, padding='SAME', activation = tf.nn.relu, input_shape=(224,224,3)))\n",
    "    # Max Pooling\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size= 2, strides= 2, padding= 'SAME'))\n",
    "\n",
    "\n",
    "    # 두 번째 Convolutional Layer\n",
    "    model.add(keras.layers.Conv2D(filters=256, kernel_size=5, strides=1, padding='SAME', activation = tf.nn.relu))\n",
    "    # Max Pooling\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size= 2, strides= 2, padding='SAME'))\n",
    "\n",
    "\n",
    "    # 세 번째 Convolutional Layer\n",
    "    model.add(keras.layers.Conv2D(filters=384, kernel_size= 3, strides=1, padding='SAME', activation = tf.nn.relu))\n",
    "    # 네 번째 Convolutional Layer\n",
    "    model.add(keras.layers.Conv2D(filters=384, kernel_size= 3, strides= 1, padding='SAME', activation = tf.nn.relu))\n",
    "    # 다섯 번째 Convolutional Layer\n",
    "    model.add(keras.layers.Conv2D(filters=256, kernel_size= 3, strides= 3, padding='SAME', activation = tf.nn.relu))\n",
    "    # Max Pooling\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size= 2, strides= 2, padding='SAME'))\n",
    "\n",
    "    # Connecting it to a Fully Connected layer\n",
    "    model.add(keras.layers.Flatten())\n",
    "    \n",
    "    # 첫 번째 Fully Connected Layer\n",
    "    model.add(keras.layers.Dense(4096, input_shape=(224*224*3,), activation = tf.nn.relu))\n",
    "    # Add Dropout to prevent overfitting\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    \n",
    "    # 두 번째 Fully Connected Layer\n",
    "    model.add(keras.layers.Dense(4096, activation = tf.nn.relu))\n",
    "    # Add Dropout\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    \n",
    "    # 세 번째 Fully Connected Layer\n",
    "    model.add(keras.layers.Dense(1000, activation = tf.nn.softmax))\n",
    "    \n",
    "    return model\n",
    "    \n",
    "alex = AlexNet()\n",
    "alex.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG Net\n",
    "### 개요\n",
    "VGGNet은 ILSVRC 2014년도에 2위를 한 모델로 모델의 깊이에 따른 변화를 비교할 수 있게 만든 모델입니다.\n",
    "\n",
    "### 3 x 3 Convolution\n",
    "VGGNet의 특징은 모든 Convolution Layer에 3 x 3 convolution filter를 사용한 것이 특징입니다.\n",
    "\n",
    "이전까지의 모델들은 첫 번째 Conv Layer에서는 입력 영상의 축소를 위해 11 x 11, 7 x 7의 Conv filter를 사용했습니다.\n",
    "\n",
    "https://kasausyrzlhe1066469.cdn.ntruss.com/global/file/p/5d312476c290c5fc21224035/Conv_filter.png\n",
    "\n",
    "3 x 3 Conv filter를 두번 사용하면 (5 x 5)와 같고 세 번 사용하면 (7 x 7) 과 같아집니다. 그러나 3 x 3을 여러번 사용하게 되면, 연산에 드는 비용이 더 적어지기 때문에 (ex, 3 x 3 x 2 = 18 vs 5 x 5 = 25) 더 높은 성능을 낼 수 있습니다.\n",
    "\n",
    "### 구조\n",
    "https://kasausyrzlhe1066469.cdn.ntruss.com/global/file/p/5d31254a98706dba333d40f1/vgg16.png\n",
    "\n",
    "VGGNet은 VGG16, VGG19 2개의 버전이 있습니다. 숫자의 의미는 각각 16개, 19개의 Layer를 갖고 있다는 의미입니다. VGG16을 예로 들자면 아래와 같이 구성되어 있습니다.\n",
    "\n",
    "----------------\n",
    "* Convolution Layer 13개\n",
    "* Fully Connected Layer 3개\n",
    "\n",
    "-------------------------\n",
    "### 단점\n",
    "summary()로 VGGNet을 보면 굉장히 많은 파라미터를 볼 수 있습니다. 파라미터가 많기 때문에 Computation Power가 굉장히 많이 필요하고 모델이 깊어짐에 따라 Gradient Vanishing의 문제가 발생할 가능성이 크다는 단점이 있습니다.\n",
    "\n",
    "관련 링크\n",
    "\n",
    "https://arxiv.org/pdf/1409.1556.pdf\n",
    "### 실습\n",
    "Keras로 작성된 VGG16 구조를 보고 이해해보세요.\n",
    "\n",
    "3 x 3 kernel을 사용하여 VGG16()을 완성시켜보세요.\n",
    "\n",
    "filters : Output 필터의 개수 [Ex) 64의 배수로 구성해보세요. VGGNet은 최대 512 차원까지 사용합니다.]\n",
    "* kerner size = 3\n",
    "* activation function = ReLU\n",
    "* padding = ‘same’\n",
    "\n",
    "summary() 메서드를 통해 각 Layer의 구조, 필터 개수, 커널 크기 등을 확인해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "def VGG16():\n",
    "    # Sequential 모델 선언\n",
    "    model = keras.Sequential()\n",
    "    # TODO : 3 x 3 convolution만을 사용하여 VGG16 Net을 완성해보세요.\n",
    "    # 첫 번째 Conv Block\n",
    "    # 입력 Shape는 ImageNet 데이터 세트의 크기와 같은 RGB 영상 (224 x 224 x 3)입니다.\n",
    "    model.add(keras.layers.Conv2D(filters = 64, kernel_size = 3, activation= tf.nn.relu, padding= 'SAME', input_shape = (224, 224, 3)))\n",
    "    model.add(keras.layers.Conv2D(filters = 64, kernel_size = 3, activation= tf.nn.relu, padding= 'SAME'))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
    "    \n",
    "    # 두 번째 Conv Block\n",
    "    model.add(keras.layers.Conv2D(filters = 128, kernel_size = 3, activation= tf.nn.relu, padding= 'SAME'))\n",
    "    model.add(keras.layers.Conv2D(filters = 128, kernel_size = 3, activation= tf.nn.relu, padding= 'SAME'))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
    "    \n",
    "    # 세 번째 Conv Block\n",
    "    model.add(keras.layers.Conv2D(filters = 256, kernel_size = 3, activation= tf.nn.relu, padding= 'SAME'))\n",
    "    model.add(keras.layers.Conv2D(filters = 256, kernel_size = 3, activation= tf.nn.relu, padding= 'SAME'))\n",
    "    model.add(keras.layers.Conv2D(filters = 256, kernel_size = 3, activation= tf.nn.relu, padding= 'SAME'))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
    "    \n",
    "    # 네 번째 Conv Block\n",
    "    model.add(keras.layers.Conv2D(filters = 512, kernel_size = 3, activation= tf.nn.relu, padding= 'SAME'))\n",
    "    model.add(keras.layers.Conv2D(filters = 512, kernel_size = 3, activation= tf.nn.relu, padding= 'SAME'))\n",
    "    model.add(keras.layers.Conv2D(filters = 512, kernel_size = 3, activation= tf.nn.relu, padding= 'SAME'))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
    "    \n",
    "    # 다섯 번째 Conv Block\n",
    "    model.add(keras.layers.Conv2D(filters = 512, kernel_size = 3, activation= tf.nn.relu, padding= 'SAME'))\n",
    "    model.add(keras.layers.Conv2D(filters = 512, kernel_size = 3, activation= tf.nn.relu, padding= 'SAME'))\n",
    "    model.add(keras.layers.Conv2D(filters = 512, kernel_size = 3, activation= tf.nn.relu, padding= 'SAME'))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
    "    \n",
    "    # Fully Connected Layer\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(4096, activation= tf.nn.relu))\n",
    "    model.add(keras.layers.Dense(4096, activation= tf.nn.relu))\n",
    "    model.add(keras.layers.Dense(1000, activation= tf.nn.softmax))\n",
    "    \n",
    "    return model\n",
    "\n",
    "vgg16 = VGG16()\n",
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoogleNet\n",
    "### 개요\n",
    "GoogleNet은 ILSVRC 2014에서 우승한 CNN 모델로 Inception이라는 개념을 처음 도입한 모델입니다.\n",
    "\n",
    "### Inception Module\n",
    "\n",
    "실제로 영화 ‘인셉션’ 장면에서 이름을 따와 Inception Module이라 부릅니다.\n",
    "\n",
    "Inception Module은 아래와 같은 구조를 가지고 있습니다.\n",
    "\n",
    "https://kasausyrzlhe1066469.cdn.ntruss.com/global/file/p/5d314559629018b0edee8001/Inception..JPG\n",
    "\n",
    "Input Layer에 대해 크기가 다른 Convolution연산을 적용하여 다양한 Feature를 학습할 수 있도록 했습니다.\n",
    "\n",
    "연산량이 많아지는 것을 해결하기위해 1 x 1 Convolution을 통해 Feature Dimension을 감소시켰습니다.\n",
    "\n",
    "### Auxiliary Classifier\n",
    "모델이 깊어짐에 따라 생기는 Gradient Vanishing 문제를 해결하기 위해 중간중간 Auxiliary Classifier를 달아 중간에서 Loss를 구할 수 있도록 했습니다.\n",
    "\n",
    "Auxiliary Classifier는 학습을 할 때만 덧붙이고 테스트를 할때에는 마지막 Classifier만 사용합니다.\n",
    "\n",
    "### 구조\n",
    "GoogleNet은 마지막 끝단에서 파라미터가 많은 FC layer를 제거하고 Average Pooling으로 학습된 값들을 평균을 냅니다.\n",
    "\n",
    "모델이 깊어지면서 Convolution Layer 연산만으로도 충분히 Feature를 학습했기 때문에 평균만을 구해도 충분히 성능이 나온다고 생각했기 때문입니다.\n",
    "\n",
    "실제로 GoogleNet은 FC layer를 제거함으로써 AlexNet보다 약 12배 적은 파라미터를 사용합니다.\n",
    "\n",
    "---------------------\n",
    "* Inception module : 9개\n",
    "* Auxiliary Classifier : 3개\n",
    "* FC layer 대신 Average Pooling 사용\n",
    "\n",
    "--------------------------------\n",
    "GoogleNet에 대한 전체적인 구조는 아래 관련 링크 (Figure 3) 에서 확인해 보겠습니다.\n",
    "\n",
    "관련 링크\n",
    "\n",
    "https://www.cs.unc.edu/~wliu/papers/GoogLeNet.pdf\n",
    "### 실습\n",
    "Keras로 작성된 GoogleNet 구조를 보고 이해해보세요.\n",
    "\n",
    "설명에 나온 그림을 보고 Inception_block()을 완성해보세요.\n",
    "\n",
    "Auxiliary_classifier()가 어떻게 구성되어 있고 GoogleNet 모델에 어떻게 적용되는지 확인해보세요.\n",
    "\n",
    "summary() 메서드를 통해 각 Layer의 구조, 필터 개수, 커널 크기 등을 확인하고 관련 링크의 Table 1과 비교해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0805 18:19:09.280721 15668 nn_ops.py:4220] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0805 18:19:10.088694 15668 nn_ops.py:4220] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 112, 112, 64) 9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 56, 56, 64)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 56, 56, 192)  110784      max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 28, 28, 192)  0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 28, 28, 96)   18528       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 28, 28, 16)   3088        max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 28, 28, 192)  0           max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 28, 28, 64)   12352       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 28, 28, 128)  110720      conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 28, 28, 32)   12832       conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 28, 28, 32)   6176        max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 28, 28, 256)  0           conv2d_24[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "                                                                 conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 28, 28, 128)  32896       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 28, 28, 32)   8224        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 28, 28, 256)  0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 28, 28, 128)  32896       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 28, 28, 192)  221376      conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 28, 28, 96)   76896       conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 28, 28, 64)   16448       max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 28, 28, 480)  0           conv2d_30[0][0]                  \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "                                                                 conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 14, 14, 480)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 14, 14, 96)   46176       max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 14, 14, 16)   7696        max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 14, 14, 480)  0           max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 14, 14, 192)  92352       max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 14, 14, 208)  179920      conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 14, 14, 48)   19248       conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 14, 14, 64)   30784       max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 512)  0           conv2d_36[0][0]                  \n",
      "                                                                 conv2d_38[0][0]                  \n",
      "                                                                 conv2d_40[0][0]                  \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 14, 14, 112)  57456       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 14, 14, 24)   12312       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 14, 14, 512)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 14, 14, 160)  82080       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 14, 14, 224)  226016      conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 14, 14, 64)   38464       conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 14, 14, 64)   32832       max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 14, 14, 512)  0           conv2d_42[0][0]                  \n",
      "                                                                 conv2d_44[0][0]                  \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 14, 14, 128)  65664       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 14, 14, 24)   12312       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 14, 14, 512)  0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 14, 14, 128)  65664       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 14, 14, 256)  295168      conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 14, 14, 64)   38464       conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 14, 14, 64)   32832       max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 14, 14, 512)  0           conv2d_49[0][0]                  \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "                                                                 conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 14, 14, 144)  73872       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 14, 14, 32)   16416       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 14, 14, 512)  0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 14, 14, 112)  57456       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 14, 14, 288)  373536      conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 14, 14, 64)   51264       conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 14, 14, 64)   32832       max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 14, 14, 528)  0           conv2d_55[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "                                                                 conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 14, 14, 160)  84640       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 14, 14, 32)   16928       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 14, 14, 528)  0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 14, 14, 256)  135424      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 14, 14, 320)  461120      conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 14, 14, 128)  102528      conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 14, 14, 128)  67712       max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 14, 14, 832)  0           conv2d_61[0][0]                  \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "                                                                 conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 7, 7, 832)    0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 7, 7, 160)    133280      max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 7, 7, 32)     26656       max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 7, 7, 832)    0           max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 7, 7, 256)    213248      max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 7, 7, 320)    461120      conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 7, 7, 128)    102528      conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 7, 7, 128)    106624      max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 7, 7, 832)    0           conv2d_68[0][0]                  \n",
      "                                                                 conv2d_70[0][0]                  \n",
      "                                                                 conv2d_72[0][0]                  \n",
      "                                                                 conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 4, 4, 512)    0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 4, 4, 832)    0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 7, 7, 192)    159936      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 7, 7, 48)     39984       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D) (None, 7, 7, 832)    0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 4, 4, 128)    65664       average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 4, 4, 128)    106624      average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 7, 7, 384)    319872      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 7, 7, 384)    663936      conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 7, 7, 128)    153728      conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 7, 7, 128)    106624      max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 2048)         0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 2048)         0           conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 7, 7, 1024)   0           conv2d_74[0][0]                  \n",
      "                                                                 conv2d_76[0][0]                  \n",
      "                                                                 conv2d_78[0][0]                  \n",
      "                                                                 conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         2098176     flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1024)         2098176     flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 1, 1, 1024)   0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024)         0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1, 1, 1024)   0           average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1000)         1025000     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1000)         1025000     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1, 1, 1000)   1025000     dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 13,413,032\n",
      "Trainable params: 13,413,032\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, AveragePooling2D, Dropout, Flatten, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Incetion 모듈 with 1 x 1 Convolution\n",
    "def inception_block(input_layer, filter1, filter2, filter3, reduce1, reduce2, pool_proj):\n",
    "    # TODO : 1 x 1 Convolution 수행\n",
    "    conv1x1 = Conv2D(filter1, kernel_size=(1,1), padding='SAME', activation='relu')(input_layer)\n",
    "    \n",
    "    # TODO : 1 x 1 Convolution 후 3 x 3 Convolution 수행\n",
    "    conv3x3_reduce = Conv2D(reduce1, kernel_size=(1,1), padding='same', activation='relu')(input_layer)\n",
    "    conv3x3 = Conv2D(filter2, kernel_size=(3,3), padding='same', activation='relu')(conv3x3_reduce)\n",
    "    \n",
    "    # TODO : 1 x 1 Convolution 후 5 x 5 Convolution 수행\n",
    "    conv5x5_reduce = Conv2D(reduce2, kernel_size=(1,1), padding='same', activation='relu')(input_layer)\n",
    "    conv5x5 = Conv2D(filter3, kernel_size=(5,5), padding='same', activation='relu')(conv5x5_reduce)\n",
    "    \n",
    "    # TODO : Max pooling 후 1 x 1 Convolution 수행\n",
    "    pooling = MaxPooling2D((3,3), strides=(1,1), padding='same')(input_layer)\n",
    "    pool_proj = Conv2D(pool_proj, kernel_size=(1,1), padding='same', activation='relu')(pooling)\n",
    "    \n",
    "    # TODO : 개별적으로 연산이 끝난 후 Feature map을 합쳐줍니다.\n",
    "    output_layer = concatenate([conv1x1,conv3x3,conv5x5,pool_proj])\n",
    "    return output_layer\n",
    "\n",
    "# Gradient Vanishing Problem을 막기 위한 Auxiliary_classifier\n",
    "def Auxiliary_classifier(input_layer, filter1, dense1, dense2, drop_prob):\n",
    "    loss_ave_pool = AveragePooling2D(pool_size= 5, strides= 3)(input_layer)\n",
    "    loss_conv = Conv2D(filter1, kernel_size = (1,1), padding='same', activation='relu', kernel_regularizer=l2(0.0002))(loss_ave_pool)\n",
    "    loss_flat = Flatten()(loss_conv)\n",
    "    loss_fc = Dense(dense1, kernel_regularizer=l2(0.0002), activation='relu')(loss_flat)\n",
    "    loss_drop_fc = Dropout(drop_prob)(loss_fc)\n",
    "    # 총 1000개의 클래스를 분류하기 때문에 마지막 node의 개수는 1000개입니다.\n",
    "    loss_classifier = Dense(dense2, kernel_regularizer=l2(0.0002), activation='softmax')(loss_drop_fc)\n",
    "    \n",
    "    return loss_classifier\n",
    "\n",
    "# 입력 선언\n",
    "shape = (224,224,3)\n",
    "inputs = Input(shape)\n",
    "\n",
    "# 초기 입력의 크기를 줄이기 위한 Convolution Layer\n",
    "conv_7x7 = Conv2D(64, kernel_size=(7,7), strides= (2,2), padding='same', activation='relu', kernel_regularizer=l2(0.0002))(inputs)\n",
    "max_pool1 = MaxPooling2D((3,3), strides=(2,2), padding='same')(conv_7x7)\n",
    "conv_3x3 = Conv2D(192, (3,3),strides=(1,1), padding='same', activation='relu', kernel_regularizer=l2(0.0002))(max_pool1)\n",
    "max_pool2 = MaxPooling2D((3,3), strides=(2,2), padding='same')(conv_3x3)\n",
    "\n",
    "# Inception 모듈을 쌓습니다.\n",
    "inception_reduce_1 = inception_block(max_pool2, 64, 128, 32, 96, 16, 32)\n",
    "inception_reduce_2 = inception_block(inception_reduce_1, 128, 192, 96, 128, 32, 64)\n",
    "\n",
    "# Max Pooling Layer로 Feature map의 크기를 줄입니다.\n",
    "max_pool3 = MaxPooling2D((3,3), strides=(2,2), padding='same')(inception_reduce_2)\n",
    "\n",
    "# Inception 모듈을 쌓습니다.\n",
    "inception_reduce_3 = inception_block(max_pool3, 192, 208, 48, 96, 16, 64)\n",
    "inception_reduce_4 = inception_block(inception_reduce_3, 160, 224, 64, 112, 24, 64)\n",
    "\n",
    "# 첫 번째 Auxiliary Classifier를 4번째 Inception 모듈 뒤에 넣어줍니다.\n",
    "loss_classifier1 = Auxiliary_classifier(inception_reduce_4, 128, 1024, 1000, 0.7)\n",
    "\n",
    "# Inception 모듈을 쌓습니다.\n",
    "inception_reduce_5 = inception_block(inception_reduce_4, 128, 256, 64, 128, 24, 64)\n",
    "inception_reduce_6 = inception_block(inception_reduce_5, 112, 288, 64, 144, 32, 64)\n",
    "inception_reduce_7 = inception_block(inception_reduce_6, 256, 320, 128, 160, 32, 128)\n",
    "\n",
    "# Max Pooling Layer로 Feature map의 크기를 줄입니다.\n",
    "max_pool4 = MaxPooling2D((3,3), strides=(2,2), padding='same')(inception_reduce_7)\n",
    "\n",
    "# 두 번째 Auxiliary Classifier를 7번째 Inception 모듈 뒤에 넣어줍니다.\n",
    "loss_classifier2 = Auxiliary_classifier(inception_reduce_7, 128, 1024, 1000, 0.7)\n",
    "\n",
    "# Inception 모듈을 쌓습니다.\n",
    "inception_reduce_8 = inception_block(max_pool4, 256, 320, 128, 160, 32, 128)\n",
    "inception_reduce_9 = inception_block(inception_reduce_8, 384, 384, 128, 192, 48, 128)\n",
    "\n",
    "# Average Pooling Layer로 학습된 Feature들의 평균을 구해줍니다.\n",
    "avg_pool = AveragePooling2D(pool_size= 7, strides= 1)(inception_reduce_9)\n",
    "drop_out_layer = Dropout(0.4)(avg_pool)\n",
    "\n",
    "# 마지막 최종 Class를 구분하기 위한 Classifier입니다.\n",
    "loss_classifier3 = Dense(1000)(drop_out_layer)\n",
    "\n",
    "# 작성한 GoogleNet 모델을 하나로 합쳐줍니다.\n",
    "model = Model(inputs = inputs, outputs = [loss_classifier1,loss_classifier2,loss_classifier3])\n",
    "\n",
    "# 모델 출력\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet\n",
    "ResNet은 ILSVRC 2015에서 우승한 모델로 Top -5 Error가 3.6% 밖에 안되는 굉장히 고성능의 모델입니다.\n",
    "\n",
    "TIP Top-5 Error란 모델이 예측한 최상위 5개 Class 가운데 정답이 없는 경우의 오류율을 말합니다.\n",
    "\n",
    "----------------\n",
    "### 개요\n",
    "ResNet은 굉장히 깊은 층(최대 152-Layer)까지 쌓을 수 있는 모델입니다. 모델의 층이 깊어질수록 역전파 (Backpropagation) 시 기울기가 0으로 수렴해버려 학습이 진행되지 않는Gradient Vanishing 현상이 발생합니다. 이러한 현상을 Degradation Problem이라고 합니다.\n",
    "\n",
    "ResNet은 Degradation problem을 완화하고 깊은 Layer를 가진 모델을 만들기 위해 Skip Connection이란 Residual Learning을 도입하였습니다.\n",
    "\n",
    "### Residual Learning\n",
    "기존 딥러닝 모델을 H(x)H(x) 라고 할 때, 우리는\n",
    "\n",
    "H(x) - y H(x)−y\n",
    "\n",
    "를 최소화하고 H(x)H(x)를 얻기 위해 학습을 했습니다.\n",
    "\n",
    "그러나 ResNet은 입력 (x)와 출력 H(x)의 잔차 F(x)F(x) (Residual)를 H(x) - xH(x)−x 라 가정하고\n",
    "\n",
    "F(x) = H(x) - x F(x)=H(x)−x\n",
    "\n",
    "를 찾도록 학습이 됩니다.\n",
    "\n",
    "결과적으로 출력은\n",
    "\n",
    "H(x) = F(x) + x H(x)=F(x)+x\n",
    "\n",
    "의 형태가 됩니다. 이렇게 잔차 (Residual)를 학습하는 것을 Residual Learning 이라고 합니다.\n",
    "\n",
    "그리고 모델의 입력 (x)과 잔차 (F(x))가 더해진 것을 다음 Layer의 입력으로 사용하는 것을 Skip Connection이라 합니다.\n",
    "\n",
    "### Skip Connection\n",
    "\n",
    "https://kasausyrzlhe1066469.cdn.ntruss.com/global/file/p/5d341ad553b891d0526da1ff/Residual%20Block.JPG\n",
    "\n",
    "Skip Connection을 적용한 Residual block의 모습입니다. 이렇게 입력을 출력에 더하여 다음 Layer의 입력으로 사용하게 되면 역전파시 미분 값이 적어도 1이상의 값이 나와 기울기가 0으로 수렴하는 현상을 최소화했습니다.\n",
    "\n",
    "### 구조\n",
    "ResNet에서는 두 종류의 Residual block을 사용합니다. Residual block을 쌓아 굉장히 깊은 층의 모델을 만들어냅니다.\n",
    "\n",
    "* Residual block : Feature map의 크기를 절반으로 줄이는 대신 Feature map의 Dimension을 2배로 늘리는 block입니다. Dimension을 맞추기 위해 1 x 1 Convolution을 사용한 block입니다. 이를 Projection Shortcut Connection 이라 합니다.\n",
    "\n",
    "\n",
    "* Identity block : 입력과 출력의 Dimension이 같은 경우에 사용합니다.\n",
    "\n",
    "전체적인 구조 및 자세한 사항은 아래의 링크에서 확인해보세요.\n",
    "\n",
    "관련 링크\n",
    "\n",
    "https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf\n",
    "### 실습\n",
    "작성된 ResNet() 모델을 보고 이해해보세요.\n",
    "\n",
    "identity_block()을 완성해보세요.\n",
    "\n",
    "residual_block()을 완성해보세요.\n",
    "\n",
    "summary()를 통해 모델의 구성 요소와 파라미터 개수 등을 확인해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 112, 112, 64) 9472        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 112, 112, 64) 256         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 112, 112, 64) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling2D) (None, 55, 55, 64)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 55, 55, 64)   4160        max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 55, 55, 64)   256         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 55, 55, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 55, 55, 64)   36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 55, 55, 64)   256         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 55, 55, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 55, 55, 256)  16640       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 55, 55, 256)  16640       max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 55, 55, 256)  1024        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 55, 55, 256)  1024        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 55, 55, 256)  0           batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 55, 55, 256)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 55, 55, 64)   16448       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 55, 55, 64)   256         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 55, 55, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 55, 55, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 55, 55, 64)   256         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 55, 55, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 55, 55, 256)  16640       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 55, 55, 256)  1024        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 55, 55, 256)  0           batch_normalization_7[0][0]      \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 55, 55, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 55, 55, 64)   16448       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 55, 55, 64)   256         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 55, 55, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 55, 55, 64)   36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 55, 55, 64)   256         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 55, 55, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 55, 55, 256)  16640       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 55, 55, 256)  1024        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 55, 55, 256)  0           batch_normalization_10[0][0]     \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 55, 55, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 28, 28, 128)  32896       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 28, 28, 128)  512         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 28, 28, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 28, 28, 128)  147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 28, 28, 128)  512         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 28, 28, 512)  66048       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 28, 28, 512)  131584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 28, 28, 512)  2048        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 28, 28, 512)  2048        conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 28, 28, 512)  0           batch_normalization_13[0][0]     \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 512)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 28, 28, 128)  65664       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 28, 28, 128)  512         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 28, 28, 128)  147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 28, 28, 128)  512         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 28, 28, 512)  66048       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 28, 28, 512)  2048        conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           batch_normalization_17[0][0]     \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 28, 28, 128)  65664       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 28, 28, 128)  512         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 128)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 28, 28, 128)  147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 28, 28, 128)  512         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 28, 28, 512)  66048       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 28, 28, 512)  2048        conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           batch_normalization_20[0][0]     \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 28, 28, 128)  65664       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 28, 28, 128)  512         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 128)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 28, 28, 128)  147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 28, 28, 128)  512         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 28, 28, 512)  66048       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 28, 28, 512)  2048        conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           batch_normalization_23[0][0]     \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 14, 14, 256)  131328      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 14, 14, 256)  1024        conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 14, 14, 256)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 14, 14, 256)  590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 14, 14, 256)  1024        conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 14, 14, 1024) 263168      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 14, 14, 1024) 525312      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 14, 14, 1024) 4096        conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 14, 14, 1024) 4096        conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_26[0][0]     \n",
      "                                                                 batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 1024) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 14, 14, 256)  262400      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 14, 14, 256)  1024        conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 256)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 14, 14, 256)  590080      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 14, 14, 256)  1024        conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 14, 14, 1024) 263168      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 14, 14, 1024) 4096        conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_30[0][0]     \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 14, 14, 256)  262400      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 14, 14, 256)  1024        conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 256)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 14, 14, 256)  590080      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 14, 14, 256)  1024        conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 14, 14, 1024) 263168      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 14, 14, 1024) 4096        conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_33[0][0]     \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 14, 14, 256)  262400      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 14, 14, 256)  1024        conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 256)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 14, 14, 256)  590080      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 14, 14, 256)  1024        conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 14, 14, 1024) 263168      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 14, 14, 1024) 4096        conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_36[0][0]     \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 14, 14, 256)  262400      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 14, 14, 256)  1024        conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 256)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 14, 14, 256)  590080      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 14, 14, 256)  1024        conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 14, 14, 1024) 263168      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 14, 14, 1024) 4096        conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_39[0][0]     \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 14, 14, 256)  262400      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 14, 14, 256)  1024        conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 256)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 14, 14, 256)  590080      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 14, 14, 256)  1024        conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 14, 14, 1024) 263168      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 14, 14, 1024) 4096        conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_42[0][0]     \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 7, 7, 512)    524800      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 7, 512)    2048        conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 512)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 7, 7, 512)    2359808     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 512)    2048        conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 7, 7, 2048)   1050624     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 7, 7, 2048)   2099200     activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 2048)   8192        conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 2048)   8192        conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_45[0][0]     \n",
      "                                                                 batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 2048)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 7, 7, 512)    1049088     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 512)    2048        conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 512)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 7, 7, 512)    2359808     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 512)    2048        conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 7, 7, 2048)   1050624     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 2048)   8192        conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_49[0][0]     \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 7, 7, 512)    1049088     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 512)    2048        conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 512)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 7, 7, 512)    2359808     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 512)    2048        conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 7, 7, 2048)   1050624     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 2048)   8192        conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_52[0][0]     \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 1, 1, 2048)   0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 2048)         0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1000)         2049000     flatten_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import add, Input,Dense,Activation, Flatten, Conv2D, MaxPooling2D, GlobalMaxPooling2D, ZeroPadding2D, AveragePooling2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "# 입력과 출력의 Dimension이 같은 경우 사용합니다.\n",
    "def identity_block(input_tensor, kernel_size, filters):\n",
    "    \n",
    "    filters1, filters2, filters3 = filters\n",
    "    \n",
    "    x = Conv2D(filters1, (1, 1))(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # 입력(x) : input_tensor와 F(x) : x를 더해줍니다.\n",
    "    # TODO : add()와 Activation() 메서드를 사용해서 relu(F(x) + x) 의 형태로 만들어보세요. \n",
    "    x = add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def residual_block(input_tensor, kernel_size, filters, strides=(2, 2)):\n",
    "    filters1 , filters2 , filters3 = filters\n",
    "    \n",
    "    # 입력 Feature Map의 Size를 1/2로 줄이는 대신 Feature map의 Dimension을 2배로 늘려줍니다.\n",
    "    x = Conv2D(filters1, (1, 1), strides=strides)(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # TODO : Projection Shortcut Connection을 구현해보세요.\n",
    "    # 1 x 1 Convolution 연산을 수행하여 Dimension을 2배로 증가시키고\n",
    "    # 입력 Feature map의 size를 1/2로 축소시켜보세요.\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides)(input_tensor)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    # F(x) : x와 Shortcut Connection : shortcut을 더해줍니다.\n",
    "    # TODO : add()와 Activation() 메서드를 사용해서 relu(F(x) + shortcut) 의 형태로 만들어보세요.\n",
    "    x = add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def ResNet50():\n",
    "    # 입력 이미지의 Shape을 정해줍니다.\n",
    "    shape = (224,224,3)\n",
    "    inputs = Input(shape)\n",
    "    \n",
    "    # 입력 영상의 크기를 줄이기 위한 Conv & Max-pooling\n",
    "    x = ZeroPadding2D((3, 3))(inputs)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    \n",
    "    # 첫 번째 Residual Block (입력 영상 Size 2배 축소 / Dimension 2배 증가)\n",
    "    x = residual_block(x, 3, [64, 64, 256], strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256])\n",
    "    x = identity_block(x, 3, [64, 64, 256])\n",
    "    \n",
    "    \n",
    "    # 두 번째 Residual Block (입력 영상 Size 2배 축소 / Dimension 2배 증가)\n",
    "    x = residual_block(x, 3, [128, 128, 512])\n",
    "    x = identity_block(x, 3, [128, 128, 512])\n",
    "    x = identity_block(x, 3, [128, 128, 512])\n",
    "    x = identity_block(x, 3, [128, 128, 512])\n",
    "    \n",
    "    # 세 번째 Residual Block (입력 영상 Size 2배 축소 / Dimension 2배 증가)\n",
    "    x = residual_block(x, 3, [256, 256, 1024])\n",
    "    x = identity_block(x, 3, [256, 256, 1024])\n",
    "    x = identity_block(x, 3, [256, 256, 1024])\n",
    "    x = identity_block(x, 3, [256, 256, 1024])\n",
    "    x = identity_block(x, 3, [256, 256, 1024])\n",
    "    x = identity_block(x, 3, [256, 256, 1024])\n",
    "    \n",
    "    # 네 번째 Residual Block (입력 영상 Size 2배 축소 / Dimension 2배 증가)\n",
    "    x = residual_block(x, 3, [512, 512, 2048])\n",
    "    x = identity_block(x, 3, [512, 512, 2048])\n",
    "    x = identity_block(x, 3, [512, 512, 2048])\n",
    "\n",
    "    # 마지막단에서 FC layer를 쓰지 않고 단순히 Averaging 합니다.\n",
    "    x = AveragePooling2D((7, 7))(x)\n",
    "    x = Flatten()(x)\n",
    "    # 1000개의 Class 구분\n",
    "    x = Dense(1000, activation='softmax')(x)\n",
    "    \n",
    "    # 모델 구성\n",
    "    model = Model(inputs, x)\n",
    "    return model\n",
    "\n",
    "model = ResNet50()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception & Residual block 구현\n",
    "앞서 실습에서 다뤘던 GoogleNet과 ResNet의 주요 구성 요소인 Inception 모듈과 Residual Block을 구현해보겠습니다.\n",
    "\n",
    "### Inception Module\n",
    "https://kasausyrzlhe1066469.cdn.ntruss.com/global/file/p/5d353465b4c4643a30270368/Residual%20Block.JPG\n",
    "\n",
    "위의 그림과 같은 형태의 Inception Module을 만들어보세요.\n",
    "\n",
    "### Residual Block\n",
    "https://kasausyrzlhe1066469.cdn.ntruss.com/global/file/p/5d353465b4c4643a30270368/Residual%20Block.JPG\n",
    "\n",
    "위의 그림과 같은 형태의 Residual Block을 만들어보세요.\n",
    "\n",
    "### 미션\n",
    "TODO를 따라 inception_block()을 채워보세요.\n",
    "\n",
    "TODO를 따라 identity_block()을 채워보세요.\n",
    "\n",
    "TIP!\n",
    "\n",
    "filters, kernel_size, padding, activation 를 알맞게 설정해보세요.\n",
    "\n",
    "이전 입력이 어디로 연결되어야 하는지 잘 확인해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, concatenate, BatchNormalization, Activation, add\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "# Incetion 모듈 with 1 x 1 Convolution\n",
    "def inception_block(input_layer, filter1, filter2, filter3, reduce1, reduce2, pool_proj):\n",
    "    # TODO : 1 x 1 Convolution Layer를 만들어주세요\n",
    "    conv1x1 = Conv2D(filter1, kernel_size=(1,1), padding='SAME', activation='relu')(input_layer)\n",
    "    \n",
    "    # TODO : 1 x 1 Convolution 후 3 x 3 Convolution 수행\n",
    "    conv3x3_reduce = Conv2D(reduce1, kernel_size=(1,1), padding='same', activation='relu')(input_layer)\n",
    "    conv3x3 = Conv2D(filter2, kernel_size=(3,3), padding='same', activation='relu')(conv3x3_reduce)\n",
    "    \n",
    "    # TODO : 1 x 1 Convolution 후 5 x 5 Convolution 수행\n",
    "    conv5x5_reduce = Conv2D(reduce2, kernel_size=(1,1), padding='same', activation='relu')(input_layer)\n",
    "    conv5x5 = Conv2D(filter3, kernel_size=(5,5), padding='same', activation='relu')(conv5x5_reduce)\n",
    "    \n",
    "    # TODO : Max pooling 후 1 x 1 Convolution 수행\n",
    "    pooling = MaxPooling2D((3,3), strides=(1,1), padding='same')(input_layer)\n",
    "    pool_proj = Conv2D(pool_proj, kernel_size=(1,1), padding='same', activation='relu')(pooling)\n",
    "    \n",
    "    # TODO : 개별적으로 연산이 끝난 후 Feature map을 합쳐줍니다.\n",
    "    output_layer = concatenate([conv1x1,conv3x3,conv5x5,pool_proj])\n",
    "    \n",
    "    return output_layer, conv1x1, conv3x3, conv3x3_reduce, conv5x5, conv5x5_reduce, pooling, pool_proj\n",
    "\n",
    "# ResNet의 핵심 구성 요소인 Residual Block입니다.\n",
    "def residual_block(input_tensor, kernel_size, filters):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    \n",
    "    # TODO : 1 x 1 Conv -> 3 x 3 conv -> 1 x 1 conv 순서로 Block을 구성해보세요.\n",
    "    # Convolution 연산이 끝나면 BatchNormalization과 Activation Layer를 더해주세요.\n",
    "    # BatchNormalization에 대해서는 다음 장에서 자세하게 다룰 예정입니다.\n",
    "    \n",
    "    conv1 = Conv2D (filters1, kernel_size=1, strides=1, padding = 'SAME')(input_tensor)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "\n",
    "    conv2 = Conv2D(filters2,kernel_size=kernel_size, padding='same')(conv1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(filters3, (1, 1))(conv2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    \n",
    "    # 입력(x) : input_tensor와 F(x) : x를 더해줍니다.\n",
    "    # TODO : add()와 Activation() 메서드를 사용해서 relu(F(x) + x) 의 형태로 만들어보세요.\n",
    "    residual = add([conv3, input_tensor])\n",
    "    residual = BatchNormalization()(residual)\n",
    "    return residual, conv1, conv2, conv3\n",
    "\n",
    "# 입력 Shape 설정합니다.\n",
    "shape = (28,28,1)\n",
    "inputs = Input(shape)\n",
    "\n",
    "# Inception Block을 불러옵니다.\n",
    "[output_layer, conv1x1, conv3x3, conv3x3_reduce, conv5x5, conv5x5_reduce, pooling, pool_proj] = inception_block(inputs, 64, 128, 32, 96, 16, 32)\n",
    "# Residual Block을 불러옵니다.\n",
    "[residual, conv1, conv2, conv3] = residual_block(inputs, 3, [64,64, 256])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
